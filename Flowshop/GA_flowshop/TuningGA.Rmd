---
title: "Tuning a genetic algorithm"
author: "Jose M Sallan"
date: "23/03/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Tuning a genetic algorithm

In this document, we will report a experiment of tuning a genetic algorithm implemented with the GA package, developed by Luca Scrocca:

https://cran.r-project.org/web/packages/GA/vignettes/GA.html

This is a large experiment, including ten instances and up to six parameters to tune. You should read first the **Tuning a simulated annealing**, where I introduce the tools available in R for experimental design in a smaller experiment.

The parameters to tune here are:

* **Selection operator:** linear rank `gaperm_lrSelection`, and nonlinear rank `gaperm_nlrSelection`.
* **Crossover operator:** cycle `gaperm_cxCrossover` and order `gaperm_oxCrossover` crossover operators.
* **Mutation operator:** insertion `gaperm_ismMutation` and swap `gaperm_swMutation` operators.

These operators are defined with the `gaControl` function. For additional documentation about GA operators, you can look at:

http://www.rubicite.com/Tutorials/GeneticAlgorithms.aspx

In addition to operators, we need to test for several numerical parameters:

* **Population size** vill take values of 50 and 100 solutions.
* **Crossover probability** values will be 1 and 0.8.
* **Mutation probability** will take values of 0.1, 0.2 and 0.5.

# Instances and performance measure

We will use the Taillard instances of the flow shop for 5 machines and 20 jobs. These can be reached with the `combheuristics` package:

```{r}
library(combheuristics)
instance_list <- Taillard_FS$tai.20.5
```

# The experimental grid

There are 10 instances in this list, so we will to introduce an instance variable to refer to each instance. We will perform five runs for each combination of parameters, each with a different value of seed. Then, the experimental grid is:

```{r}
parameter_values <- expand.grid(instance=1:10, selection=c("gaperm_lrSelection", "gaperm_nlrSelection"), crossover=c("gaperm_cxCrossover", "gaperm_oxCrossover"), mutation=c("gaperm_ismMutation", "gaperm_swMutation"), popsize=c(50, 100), pcrossover=c(1, 0.8), pmutation=c(0.1, 0.2, 0.5), seed=1:5)
```

This grid has `r nrow(parameter_values)` elements, including instance value and multiple runs for each combination of parameters.

In the Taillard instances, we have an upper and lower bound of the optimal solution, so we can define a performance measurement:

\[
\frac{z - z_{lower}}{z_{upper} - z_{lower}}
\]

# Running the experiment

To run the genetic algorithms, we need the objective function:

```{r}
makespanGA <- function(M, sol){
  
  m <- dim(M)[1]
  n <- dim(M)[2]
  
  M <- M[ , sol]
  
  for(j in 2:n) M[1, j] <- M[1, (j-1)] + M[1, j]
  for(i in 2:m) M[i, 1] <- M[(i-1), 1] + M[i, 1]
  
  for(i in 2:m)
    for(j in 2:n)
      M[i,j] <- max(M[i-1,j], M[i, j-1]) + M[i, j]
  
  
  return(-M[m, n])
}
```


The function to run the experiment is:

```{r}
testGAFS <- function(list, params){
  instance <- list[[as.numeric(params[1])]]
  
  gaControl("permutation" = list(selection = params[2], crossover = params[3], mutation = params[4]))
  
  ga_output <- ga(type = "permutation", fitness = makespanGA, M=instance$tij, lower = 1, upper = instance$n, popSize=as.numeric(params[5]), maxiter = 150, pmutation = as.numeric(params[6]), seed=as.numeric(params[7]), monitor = FALSE)
  
  z <- -ga_output@fitnessValue
  
  fit <- (z-instance$lower)/(instance$upper - instance$lower)
  return(fit)
}
```

We have set monitor=FALSE to avoid printing the output while running the algorithm, thus saving time.

The experiment is run making:

```{r, message=FALSE, eval=FALSE}
library(GA)
h2b <- apply(parameter_values, 1, function(x) testGAFS(list=instance_list, params=x))
```

Running this code takes several hours, so we have run the script `FineTuningGA.R`, which stores the results in `resultsGAtai20_5.csv`.

# Results evaluation

To examine the results, we will load the tidyverse:

```{r, message=FALSE}
library(tidyverse)
```


Let's load the results:

```{r}
results <- read.csv("resultsGAtai20_5.csv")
```
 
Let's obtain a summary of the mean performance for each combination of parameters for each instance. We'll add also the standard deviation of the performance parameter.

```{r}
mean_results <- results %>% group_by(instance, selection, crossover, mutation, popsize, pcrossover, pmutation) %>% summarise(mean=mean(h2b), sd=sd(h2b))
```

Let's retain which combinations of parameters are the best for each instance:

```{r}
mean_results %>% group_by(instance) %>% filter(mean==min(mean)) %>% print(n=80)
```

From that table, we can see that genetic algorithm performance depends only on population size and probabilities of crossover and mutation. Let's show the best combination of parameters for each instance:

```{r}
library(kableExtra)
dt <- mean_results %>% group_by(instance) %>% filter(mean==min(mean)) %>% filter(row_number()==1) %>% select(popsize, pcrossover, pmutation, mean)
kable(dt) %>% kable_styling(bootstrap_options = "striped", full_width = F)
```

From this analysis, we can say that the selection, crossover and mutations operators do not have influence in the best results, and that the best results are achieved with a population size of 100. Further research may consider another analysis with default operators, larger values of population size and a wider range of probabilities of crossover and mutation.